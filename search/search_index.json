{"docs":[{"location":"/paradox.json","text":"","title":""},{"location":"/docs/index.html","text":"","title":"Blue Brain Nexus"},{"location":"/docs/index.html#blue-brain-nexus","text":"The BlueBrain Nexus is a provenance based, semantic enabled data management platform enabling the definition of an arbitrary domain of application for which there is a need to create and manage entities as well as their relations (e.g. provenance). For example, the domain of application managed by the Nexus platform deployed at Blue Brain is to digitally reconstruct and simulate the brain.\nAt the heart of the BlueBrain Nexus platform lies the Knowledge Graph; at BlueBrain, it will allow scientists to:\nRegister and manage neuroscience relevant entity types through schemas that can reuse or extend community defined schemas (e.g. schema.org, bioschema.org, W3C-PROV) and ontologies (e.g. brain parcellation schemes, cell types, taxonomy). Submit data to the platform and describe their provenance using the W3C PROV model. Provenance is about how data or things are generated (e.g. protocols, methods used…), when (e.g. timeline) and by whom (e.g. people, software…). Provenance supports the data reliability and quality assessment as well as enables workflow reproducibility. Platform users can submit data either through web forms or programmatic interfaces. Search, discover, reuse and derive high-quality neuroscience data generated within and outside the platform for the purpose of driving their own scientific endeavours. Data can be examined by species, contributing laboratory, methodology, brain region, and data type, thereby allowing functionality not currently available elsewhere. The data are predominantly organized into atlases (e.g. Allen CCF, Waxholm) and linked to the KnowledgeSpace – a collaborative community-based encyclopedia linking brain research concepts to the latest data, models and literature.\nIt is to be noted that many other scientific fields (Astronomy, Agriculture, Bioinformatics, Pharmaceutical Industry, …) are in need of such a technology. Consequently, BlueBrain Nexus core technology is being developed to be agnostic of the domain it might be applied to.","title":"Blue Brain Nexus"},{"location":"/docs/index.html#nexus-components","text":"The Nexus platform is made up of a collection of services and web applications that work together to manage data stored within the system. The services and web applications are powered by a collection of libraries and tools built specifically to address the needs of the platform. Underneath it all there are popular open source technologies that we all know and love.","title":"Nexus Components"},{"location":"/docs/index.html#nexus-services","text":"","title":"Nexus Services"},{"location":"/docs/index.html#nexus-knowledgegraph","text":"This service is the heart of the BlueBrain Nexus platform. It allows users to define their domain, populate the knowledge graph with data, attach files to data. It also provides semantic search facilities to discover similar and relevant data in the platform.\nSource Code | Documentation","title":"Nexus KnowledgeGraph"},{"location":"/docs/index.html#nexus-admin","text":"This service manages the platform wide scopes for data and their configuration (i.e.: the API mapping).\nSource Code | Documentation","title":"Nexus Admin"},{"location":"/docs/index.html#nexus-iam","text":"This service manages the access to data within the platform. It makes use of configurable downstream OpenID Connect compliant identity providers to authenticate clients and manages the access controls for the entire platform.\nSource Code | Documentation","title":"Nexus IAM"},{"location":"/docs/index.html#nexus-web-applications","text":"","title":"Nexus Web Applications"},{"location":"/docs/index.html#nexus-search","text":"This web application allows users of the nexus platform to search in the knowledge graph. Beyond searching and inspecting data stored in the platform, its purpose is to enable the discovery of similar and related data.\nSource Code","title":"Nexus Search"},{"location":"/docs/index.html#nexus-explorer","text":"This web application allows users to browse the data within the system.\nSource Code","title":"Nexus Explorer"},{"location":"/docs/index.html#nexus-docs","text":"Generated documentation for the platform (this website).\nSource Code | Website","title":"Nexus Docs"},{"location":"/docs/getting-started/index.html","text":"","title":"Getting Started Guide"},{"location":"/docs/getting-started/index.html#getting-started-guide","text":"","title":"Getting Started Guide"},{"location":"/docs/getting-started/running-nexus/index.html","text":"","title":"Running Nexus"},{"location":"/docs/getting-started/running-nexus/index.html#running-nexus","text":"TBC.","title":"Running Nexus"},{"location":"/docs/getting-started/running-nexus/index.html#using-the-public-sandbox","text":"TBC.","title":"Using the public sandbox"},{"location":"/docs/getting-started/running-nexus/docker.html","text":"","title":"Run Nexus locally with Docker"},{"location":"/docs/getting-started/running-nexus/docker.html#run-nexus-locally-with-docker","text":"","title":"Run Nexus locally with Docker"},{"location":"/docs/getting-started/running-nexus/docker.html#requirements","text":"","title":"Requirements"},{"location":"/docs/getting-started/running-nexus/docker.html#docker","text":"Regardless of your OS, make sure to run a recent version of Docker (community edition). This was tested with versions 18.03.1 and above. You might need to get installation packages directly from the official Docker website if the one provided by your system package manager is outdated.\nCommand docker --version\n Example $ docker version\nDocker version 18.03.1-ce, build 9ee9f40","title":"Docker"},{"location":"/docs/getting-started/running-nexus/docker.html#memory-and-cpu-limits","text":"On macOS and Windows, Docker effectively runs containers inside a VM created by the system hypervisor. Nexus requires at least 2 CPUs and 8 GiB of memory in total. You can increase the limits in Docker settings in the menu Preferences > Advanced.","title":"Memory and CPU limits"},{"location":"/docs/getting-started/running-nexus/docker.html#initialize-docker-swarm","text":"If you’ve never used Docker Swarm or Docker Stacks before, you first need to create a swarm cluster on your local machine:\nCommand docker swarm init\n Example $ docker swarm init\nSwarm initialized: current node (***) is now a manager.\n \nTo add a worker to this swarm, run the following command:\n \ndocker swarm join --token {token} 128.178.97.243:2377\n \nTo add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.","title":"Initialize Docker Swarm"},{"location":"/docs/getting-started/running-nexus/docker.html#deployment","text":"Download the Docker Compose template and the Nginx router configuration into a directory of your choice. For instance ~/docker/nexus/.","title":"Deployment"},{"location":"/docs/getting-started/running-nexus/docker.html#starting-nexus","text":"Create a nexus deployment with Docker Stacks:\nCommand docker stack deploy nexus --compose-file=docker-compose.yaml\n Example $ cd ~/docker/nexus\n$ docker stack deploy nexus --compose-file=docker-compose.yaml\nCreating network nexus_default\nCreating config nexus_nginx\nCreating service nexus_iam\nCreating service nexus_admin\nCreating service nexus_elasticsearch\nCreating service nexus_cassandra\nCreating service nexus_kafka\nCreating service nexus_blazegraph\nCreating service nexus_router\nCreating service nexus_kg\nWait about one minute and you should be able to access Nexus locally, on the port 80:\nCommand curl http://localhost\n Example $ curl http://localhost\n{\"name\":\"kg\",\"version\":\"0.10.11\"}\nTo list running services or access logs, please refer to the documentation.","title":"Starting Nexus"},{"location":"/docs/getting-started/running-nexus/docker.html#stopping-nexus","text":"You can stop and delete the entire deployment with:\nCommand docker stack rm nexus\n Example $ docker stack rm nexus\nRemoving service nexus_admin\nRemoving service nexus_blazegraph\nRemoving service nexus_cassandra\nRemoving service nexus_elasticsearch\nRemoving service nexus_iam\nRemoving service nexus_kafka\nRemoving service nexus_kg\nRemoving service nexus_router\nRemoving config nexus_nginx\nRemoving network nexus_default\nNote As no data is persisted outside the containers, everyting will be lost once you remove the Nexus deployment. If you’d like help with creating persistent volumes, feel free to contact us on our Gitter channel.","title":"Stopping Nexus"},{"location":"/docs/getting-started/running-nexus/minikube.html","text":"","title":"Run Nexus locally with Minikube"},{"location":"/docs/getting-started/running-nexus/minikube.html#run-nexus-locally-with-minikube","text":"Minikube is a tool that makes it easy to run Kubernetes locally. Minikube runs a single-node Kubernetes cluster inside a VM on your laptop for users looking to try out Kubernetes or develop with it day-to-day.\nNote This section makes use of static assets hosted on this website; to remove the clutter please export the base of the documentation to $MINI env var: export MINI=\"https://bluebrain.github.io/nexus/docs/getting-started/running-nexus/minikube\"\nNote This page presents the necessary commands to deploy Nexus with Minikube but also examples the show the expected output. Some of the examples on this page make use of curl (https://curl.haxx.se/) and jq (https://stedolan.github.io/jq/) for formatting the json output when interacting with the services. Please install these command line tools if you’d like to run the commands in the examples. On macOS you can run: brew install curl jq","title":"Run Nexus locally with Minikube"},{"location":"/docs/getting-started/running-nexus/minikube.html#install-minikube","text":"Follow the installation instructions posted on the Minikube project page.","title":"Install Minikube"},{"location":"/docs/getting-started/running-nexus/minikube.html#minikube-install-instructions-for-macos","text":"An example for installing and running Minikube on macOS using Hyperkit after installing Docker for Mac:\nbrew install kubectl\nbrew cask install minikube\ncurl -Lo docker-machine-driver-hyperkit https://storage.googleapis.com/minikube/releases/latest/docker-machine-driver-hyperkit \\\n    && chmod +x docker-machine-driver-hyperkit \\\n    && sudo cp docker-machine-driver-hyperkit /usr/local/bin/ \\\n    && rm docker-machine-driver-hyperkit \\\n    && sudo chown root:wheel /usr/local/bin/docker-machine-driver-hyperkit \\\n    && sudo chmod u+s /usr/local/bin/docker-machine-driver-hyperkit\nTo start Minikube run (notice the cpu and memory flags, the setup requires a minimum of --cpus=2 --memory=8196):\nminikube start --cpus 6 --memory 10240 --vm-driver=hyperkit\nIf the installation is successful you can run the following command to open the Kubernetes Dashboard:\nminikube dashboard\nTo stop Minikube run:\nminikube stop\nNote After stopping minikube the vm still exists on the system; starting minikube again will preserve the deployed services. To permanently remove minikube vm run: minikube delete","title":"Minikube install instructions for macOS"},{"location":"/docs/getting-started/running-nexus/minikube.html#enable-the-ingress-addon","text":"Minikube comes with a collection of addons like the Kubernetes Dashboard but not all are enabled by default. An important one is the ingress addon which enables routing http traffic from the host into the cluster.\nTo enable the ingress addon run:\nCommand minikube addons enable ingress\n Example $ minikube addons enable ingress\ningress was successfully enabled\n$\nTo get the external IP of the cluster (to be used later in accessing services) run:\nCommand minikube addons open ingress --url | awk -F / '{print $3}' | awk -F : '{print $1}'\n Example $ minikube addons open ingress --url | awk -F / '{print $3}' | awk -F : '{print $1}'\n192.168.64.3\n$","title":"Enable the ingress addon"},{"location":"/docs/getting-started/running-nexus/minikube.html#setup-a-separate-namespace","text":"Kubernetes namespaces are logical groupings of resources which allow segregating various deployments in “virtual clusters”.\nThe default installation of Minikube creates three namespaces: kube-system, kube-public and default. This example uses a separate namespace to group Nexus specific resources.\nGet the list of available namespaces:\nCommand kubectl get namespaces\n Example $ kubectl get namespaces\nNAME          STATUS    AGE\ndefault       Active    1h\nkube-public   Active    1h\nkube-system   Active    1h\n$\nCreate the nexus namespace:\nCommand kubectl apply -f $MINI/namespace.yaml\n Example $ kubectl apply -f $MINI/namespace.yaml\nnamespace/nexus created\n$ kubectl get namespaces\nNAME          STATUS    AGE\ndefault       Active    1h\nkube-public   Active    1h\nkube-system   Active    1h\nnexus         Active    1m\n$\nDefault the kubectl to the nexus namespace:\nCommand kubectl config set-context minikube --namespace=nexus\n Example $ kubectl config set-context minikube --namespace=nexus\nContext \"minikube\" modified.\n$\nNote Every time Minikube is stopped and started again, the context and its configuration is lost. Remember to run the following commands every time you start minikube: kubectl config use-context minikube && kubectl config set-context minikube --namespace=nexus","title":"Setup a separate namespace"},{"location":"/docs/getting-started/running-nexus/minikube.html#deploy-dependent-services","text":"Nexus uses numerous off the shelf services that need to be set-up as a prerequisite. Run the following command to save the IP address of the minikube cluster in an environment variable:\nCommand export NEXUS=$(minikube addons open ingress --url | awk -F / '{print $3}' | awk -F : '{print $1}')\n Example $ export NEXUS=$(minikube addons open ingress --url | awk -F / '{print $3}' | awk -F : '{print $1}')\n$ echo $NEXUS\n192.168.64.3\n$","title":"Deploy dependent services"},{"location":"/docs/getting-started/running-nexus/minikube.html#deploy-cassandra","text":"Command kubectl apply -f $MINI/cassandra.yaml && \\\n  kubectl wait pod cassandra-0 --for condition=ready --timeout=180s\n Example $ kubectl apply -f $MINI/cassandra.yaml\nservice/cassandra created\nstatefulset.apps/cassandra created\n$ kubectl exec -it cassandra-0 -- nodetool status\nDatacenter: datacenter1\n=======================\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address     Load       Tokens       Owns (effective)  Host ID                               Rack\nUN  172.17.0.4  103.71 KiB  256          100.0%            80c0bdfa-1f5e-41aa-8a7e-f0dea7fe7ef0  rack1\n$","title":"Deploy Cassandra"},{"location":"/docs/getting-started/running-nexus/minikube.html#deploy-elasticsearch","text":"Command kubectl apply -f $MINI/elasticsearch.yaml && \\\n  kubectl wait pod elasticsearch-0 --for condition=ready --timeout=180s\n Example $ kubectl apply -f $MINI/elasticsearch.yaml\nservice/elasticsearch created\nservice/elasticsearch-discovery created\nstatefulset.apps/elasticsearch created\n$ kubectl wait pod elasticsearch-0 --for condition=ready --timeout=60s\npod/elasticsearch-0 condition met\n$ curl \"http://$NEXUS/elasticsearch\"\n{\n  \"name\" : \"elasticsearch-0\",\n  \"cluster_name\" : \"nexus-cluster\",\n  \"cluster_uuid\" : \"pvu_3bdoR0az4_9qIw0wlg\",\n  \"version\" : {\n\"number\" : \"6.3.1\",\n\"build_flavor\" : \"default\",\n\"build_type\" : \"tar\",\n\"build_hash\" : \"eb782d0\",\n\"build_date\" : \"2018-06-29T21:59:26.107521Z\",\n\"build_snapshot\" : false,\n\"lucene_version\" : \"7.3.1\",\n\"minimum_wire_compatibility_version\" : \"5.6.0\",\n\"minimum_index_compatibility_version\" : \"5.0.0\"\n  },\n  \"tagline\" : \"You Know, for Search\"\n}\n$","title":"Deploy ElasticSearch"},{"location":"/docs/getting-started/running-nexus/minikube.html#deploy-blazegraph","text":"Command kubectl apply -f $MINI/blazegraph.yaml && \\\n  kubectl wait pod blazegraph-0 --for condition=ready --timeout=180s\n Example $ kubectl apply -f $MINI/blazegraph.yaml\nservice/blazegraph created\nstatefulset.apps/blazegraph created\npersistentvolumeclaim/storage-blazegraph created\ningress.extensions/blazegraph created\n$ kubectl wait pod blazegraph-0 --for condition=ready --timeout=180s\npod/blazegraph-0 condition met\n$ curl -s -H\"Accept: application/json\" \"http://$NEXUS/blazegraph/namespace?describe-each-named-graph=false\" | head -4\n  {\n\"head\" : {\n  \"vars\" : [ \"subject\", \"predicate\", \"object\", \"context\" ]\n},\n$","title":"Deploy BlazeGraph"},{"location":"/docs/getting-started/running-nexus/minikube.html#deploy-kafka","text":"Command kubectl apply -f $MINI/zookeeper.yaml && \\\n  kubectl wait pod zookeeper-0 --for condition=ready --timeout=180s && \\\n  kubectl apply -f $MINI/kafka.yaml && \\\n  kubectl wait pod kafka-0 --for condition=ready --timeout=180s\n Example $ kubectl apply -f $MINI/zookeeper.yaml && \\\n  kubectl wait pod zookeeper-0 --for condition=ready --timeout=180s && \\\n  kubectl apply -f $MINI/kafka.yaml && \\\n  kubectl wait pod kafka-0 --for condition=ready --timeout=180s\nservice/zookeeper created\nstatefulset.apps/zookeeper created\npod/zookeeper-0 condition met\nservice/kafka created\nstatefulset.apps/kafka created\npod/kafka-0 condition met\n$","title":"Deploy Kafka"},{"location":"/docs/getting-started/running-nexus/minikube.html#deploy-nexus-services","text":"Before configuring the services a configuration map must first be created that keeps track of the “public” ip address of the minikube cluster. The following command will replace the {NEXUS} token in the config.yaml file with the value stored in the $NEXUS variable set above.\nCommand curl -s $MINI/config.yaml | sed \"s/{NEXUS}/$NEXUS/g\" | kubectl apply -f -\n Example $ curl -s $MINI/config.yaml | sed \"s/{NEXUS}/$NEXUS/g\" | kubectl apply -f -\nconfigmap/config created\n$ kubectl get configmap/config -o yaml | grep public.ip:\n  public.ip: 192.168.64.4\n$","title":"Deploy Nexus Services"},{"location":"/docs/getting-started/running-nexus/minikube.html#deploy-iam","text":"IAM is the service that manages identities and tokens via downstream OIDC providers and manages the permissions to arbitrary resources in the system.\nCommand kubectl apply -f $MINI/iam.yaml && \\\n  kubectl wait pod iam-0 --for condition=ready --timeout=180s\n Example $ kubectl apply -f $MINI/iam.yaml\nservice/iam created\nservice/iam-hd created\nstatefulset.apps/iam created\ningress.extensions/iam created\ningress.extensions/iam-direct created\n$ kubectl wait pod iam-0 --for condition=ready --timeout=180s\npod/iam-0 condition met\n$ curl -s \"http://$NEXUS/iam\" | jq\n{\n  \"name\": \"iam\",\n  \"version\": \"0.10.21\",\n  \"_links\": [\n    {\n      \"rel\": \"api\",\n      \"href\": \"http://192.168.64.6/v1/acls\"\n    }\n  ]\n}\n$ curl -s \"http://$NEXUS/v1/acls/\" | jq\n{\n  \"@context\": \"http://192.168.64.6/v1/contexts/nexus/core/iam/v0.1.0\",\n  \"acl\": [\n    {\n      \"path\": \"/\",\n      \"identity\": {\n        \"@id\": \"http://192.168.64.6/v1/anonymous\",\n        \"@type\": \"Anonymous\"\n      },\n      \"permissions\": [\n        \"read\",\n        \"own\"\n      ]\n    }\n  ]\n}\n$","title":"Deploy IAM"},{"location":"/docs/getting-started/running-nexus/minikube.html#deploy-admin","text":"Admin is the service that manages accounts (orgs and users) and projects their configuration.\nCommand kubectl apply -f $MINI/admin.yaml && \\\n  kubectl wait pod admin-0 --for condition=ready --timeout=180s\n Example $ kubectl apply -f $MINI/admin.yaml\nservice/admin created\nservice/admin-hd created\nstatefulset.apps/admin created\ningress.extensions/admin created\ningress.extensions/admin-direct created\n$ kubectl wait pod admin-0 --for condition=ready --timeout=180s\npod/admin-0 condition met\n$ curl -s \"http://$NEXUS/admin\" | jq\n{\n  \"name\": \"admin\",\n  \"version\": \"0.2.7\"\n}\n$ curl -s \"http://$NEXUS/v1/projects\" | jq # the access error is expected\n{\n  \"@context\": \"http://bluebrain.github.io/nexus/contexts/error.json\",\n  \"code\": \"UnauthorizedAccess\"\n}\n$","title":"Deploy Admin"},{"location":"/docs/getting-started/running-nexus/minikube.html#deploy-kg","text":"KG is the service that manages user defined resources, their schemas and configuration like resolvers, views etc.\nCommand kubectl apply -f $MINI/kg.yaml && \\\n  kubectl wait pod kg-0 --for condition=ready --timeout=180s\n Example $ kubectl apply -f $MINI/kg.yaml\nservice/kg created\nservice/kg-hd created\nstatefulset.apps/kg created\npersistentvolumeclaim/storage-kg created\ningress.extensions/kg created\ningress.extensions/kg-direct created\n$ kubectl wait pod kg-0 --for condition=ready --timeout=180s\npod/kg-0 condition met\n$ curl -s \"http://$NEXUS/kg\" | jq\n{\n  \"name\": \"kg\",\n  \"version\": \"0.10.11\"\n}\n$ curl -s \"http://$NEXUS/v1/resources/org/proj\" | jq # the access error is expected\n{\n  \"@context\": \"https://bluebrain.github.io/nexus/contexts/error\",\n  \"code\": \"UnauthorizedAccess\"\n}\n$","title":"Deploy KG"},{"location":"/docs/getting-started/running-nexus/on-premise-cloud.html","text":"","title":"On premise / cloud deployment"},{"location":"/docs/getting-started/running-nexus/on-premise-cloud.html#on-premise-cloud-deployment","text":"There are several things to consider when preparing to deploy Nexus “on premise” because the setup depends a lot on the various usage profiles, but the most important categories would be:\nAvailability Latency & throughput Capacity Efficient use of hardware resources Backup and restore Monitoring & alerting\nEach of the Nexus services and “off the shelf” products can be deployed as a single instance or as a cluster (with one exception at this point being BlazeGraph which doesn’t come with a clustering option). The advantages for deploying clusters are generally higher availability, capacity and throughput at the cost of higher latency, consistency and having to deal with network instability.\nThe decision to go with single node deployments or clustered deployments can be revisited later on and mixed setups (some services single node while others clustered) are also possible.\nThe Nexus distribution is made up of docker images which can be run on any host operating system and each of the “off the shelf” products also offer docker as a deployment option. We would generally recommend using a container orchestration solution like Kubernetes, OpenShift or Docker Swarm as they offer good management capabilities, discovery, load balancing and self-healing. Currently the biggest Nexus deployment is at EPFL within OpenShift.","title":"On premise / cloud deployment"},{"location":"/docs/getting-started/running-nexus/on-premise-cloud.html#choice-of-hardware","text":"Depending on the target throughput, usage profiles and data volume the hardware specification can vary greatly; please take a look at the benchmarks section to get an idea of what you should expect in terms of throughput with various hardware configurations. When the usage profiles are unknown a couple of rules of thumb should narrow the scope:\nNexus uses a collection of data stores (Cassandra, ElasticSearch, BlazeGraph) which depend performance wise to the underlying disk access, so: prefer local storage over network storage for lower latency when doing IO prefer SSD over HDDs because random access speed is more important than sequential access one exception is the file storage (attachments to resources which are stored as binary blobs on the filesystem) where the network disks should not be a cause for concern, nor random access speed; this assumes that accessing attachments is not the at the top in the usage profile All of Nexus services and most of the “off the shelf” products are built to run on top of the JVM which usually require more memory over computing power. A rough ratio of 2 CPU cores per 8GB of RAM is probably a good one (this of course depends on the CPU specification). Due to the design for scalability of Nexus services and “off the shelf” products the network is a very important characteristic of the deployment as frequent dropped packets or partitions can seriously affect the availability of the system. Clustered / distributed systems generally use some form of consensus which is significantly affected by the reliability of the network. If the reliability of the network is a concern within the target deployment then vertical scalability is desirable over horizontal scalability: fewer host nodes with better specifications is better over more commodity hardware host nodes.","title":"Choice of hardware"},{"location":"/docs/getting-started/running-nexus/on-premise-cloud.html#cassandra","text":"Nexus uses Cassandra as its primary store as it scales well in terms of reads with the number of nodes in the cluster. It offers data replication out of the box which allows the system to continue to be available in case of node failures or network partitions.\nSince this is the primary store it is the most important system to be backed up. All of the data that Nexus uses in other stores can be recomputed from the one stored in Cassandra as the other stores are used as mere indexing systems.\nPlease have a look at the Planning and Testing section in the DataStax documentation as it contains recommendations in terms of hardware and capacity.\nAs described in the architecture section the generally adopted persistence model is an EventSourced model in which the data store is used as an append only store. This has implications to the total amount of disk used by the primary store.\nA formula for computing the required disk space:\ntotal = (resource_size + nexus_metadata_size) * count * number_updates * replication_factor * 2 (compaction requirement)\nThe nexus_metadata_size varies depending on many things, but it’s generally less than or equal to the resource_size.\nAn example, assuming:\n10KB per resource 1.000.000 distinct resources 10 updates per resource replication factor of 3\n… the total required disk size would be:\n(10KB + 10KB) * 1.000.000 * 10 * 3 * 2 = 1.000.000.000KB ~= 955GB\nThe resulting size represents the total disk space of the cluster; a 5 node cluster with the data volume in the example above would have to be configured with 200GB disks per node.","title":"Cassandra"},{"location":"/docs/getting-started/intro-linked-data.html","text":"","title":"Introduction to Linked Data"},{"location":"/docs/getting-started/intro-linked-data.html#introduction-to-linked-data","text":"TBC.","title":"Introduction to Linked Data"},{"location":"/docs/getting-started/shacl.html","text":"","title":"Data validation with SHACL"},{"location":"/docs/getting-started/shacl.html#data-validation-with-shacl","text":"TBC.","title":"Data validation with SHACL"},{"location":"/docs/getting-started/example.html","text":"","title":"Data management example"},{"location":"/docs/getting-started/example.html#data-management-example","text":"TBC.","title":"Data management example"},{"location":"/docs/api/index.html","text":"","title":"API Reference"},{"location":"/docs/api/index.html#api-reference","text":"TBC.","title":"API Reference"},{"location":"/docs/api/operating-on-resources.html","text":"","title":"Operating on resources"},{"location":"/docs/api/operating-on-resources.html#operating-on-resources","text":"TBC.","title":"Operating on resources"},{"location":"/docs/api/admin-service-api.html","text":"","title":"Admin Service API"},{"location":"/docs/api/admin-service-api.html#admin-service-api","text":"TBC.","title":"Admin Service API"},{"location":"/docs/api/kg-service-api.html","text":"","title":"KnowledgeGraph Service API"},{"location":"/docs/api/kg-service-api.html#knowledgegraph-service-api","text":"TBC.","title":"KnowledgeGraph Service API"},{"location":"/docs/api/iam-service-api.html","text":"","title":"IAM Service API"},{"location":"/docs/api/iam-service-api.html#iam-service-api","text":"TBC.","title":"IAM Service API"},{"location":"/docs/api/error-signaling.html","text":"","title":"Error Signaling"},{"location":"/docs/api/error-signaling.html#error-signaling","text":"","title":"Error Signaling"},{"location":"/docs/architecture/index.html","text":"","title":"System Architecture"},{"location":"/docs/architecture/index.html#system-architecture","text":"The architecture section is to provide a comprehensive architectural overview of the Nexus platform. It presents a number of architectural views to depict various aspects of the system. It is intended to convey the significant architectural decisions which have been made on the system.\nTBC.","title":"System Architecture"},{"location":"/docs/architecture/use-cases.html","text":"","title":"Use Cases"},{"location":"/docs/architecture/use-cases.html#use-cases","text":"","title":"Use Cases"},{"location":"/docs/architecture/components.html","text":"","title":"Components"},{"location":"/docs/architecture/components.html#components","text":"","title":"Components"},{"location":"/docs/architecture/integration.html","text":"","title":"Integration"},{"location":"/docs/architecture/integration.html#integration","text":"","title":"Integration"},{"location":"/docs/architecture/systematic-service-design.html","text":"","title":"Systematic service design"},{"location":"/docs/architecture/systematic-service-design.html#systematic-service-design","text":"TBC.","title":"Systematic service design"},{"location":"/docs/roadmap/index.html","text":"","title":"Roadmap"},{"location":"/docs/roadmap/index.html#roadmap","text":"TBC.","title":"Roadmap"},{"location":"/docs/benchmarks/index.html","text":"","title":"Benchmarks"},{"location":"/docs/benchmarks/index.html#benchmarks","text":"TBC.","title":"Benchmarks"},{"location":"/docs/benchmarks/deployment-configuration.html","text":"","title":"Deployment Configuration"},{"location":"/docs/benchmarks/deployment-configuration.html#deployment-configuration","text":"TBC.","title":"Deployment Configuration"},{"location":"/docs/benchmarks/data-volumes.html","text":"","title":"Data Volumes"},{"location":"/docs/benchmarks/data-volumes.html#data-volumes","text":"TBC.","title":"Data Volumes"},{"location":"/docs/benchmarks/scenarios.html","text":"","title":"Scenarios"},{"location":"/docs/benchmarks/scenarios.html#scenarios","text":"TBC.","title":"Scenarios"},{"location":"/docs/benchmarks/results.html","text":"","title":"Results"},{"location":"/docs/benchmarks/results.html#results","text":"TBC.","title":"Results"},{"location":"/docs/additional-info/index.html","text":"","title":"Additional Information"},{"location":"/docs/additional-info/index.html#additional-information","text":"","title":"Additional Information"},{"location":"/docs/additional-info/incremental-domain-definition.html","text":"","title":"Incremental domain definition"},{"location":"/docs/additional-info/incremental-domain-definition.html#incremental-domain-definition","text":"TBC.","title":"Incremental domain definition"},{"location":"/docs/additional-info/faq.html","text":"","title":"Frequently asked questions"},{"location":"/docs/additional-info/faq.html#frequently-asked-questions","text":"TBC.","title":"Frequently asked questions"}]}